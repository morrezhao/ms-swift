"""
QA Validation Prompts.

LLM evaluates generated QA pairs and decides accept/reject.
No MC generation â€” options are provided by the QA generator directly.
"""

VALIDATION_SYSTEM_PROMPT = """You are a QA quality reviewer for a VQA benchmark.

## Task
Decide whether to ACCEPT or REJECT each question-answer pair.

## ACCEPT if ALL of the following are true:
1. The question type is valid (one of the recognized types)
2. The ground truth answer is reasonable (not 0 for distance, not negative, not empty)
3. The question is clear, unambiguous, and grammatically correct
4. All objects mentioned in the question exist in the scene (count > 0)

## REJECT if ANY of the following are true:
- Invalid answer: 0 distance, negative count, empty string, "unknown", "ambiguous"
- Missing objects: any category in the question has count = 0 in the scene
- Unclear or grammatically incorrect question
- References instance indices (e.g., "the second chair", "instance 1")

## Output Format
```json
{
  "decision": "accept" or "reject",
  "rejection_reason": "explanation if rejected, null if accepted"
}
```
"""

VALIDATION_USER_PROMPT_TEMPLATE = """## Scene Metadata
{scene_context}

## Question to Evaluate
- **Question Type**: {question_type}
- **Question**: {question}
- **Ground Truth Answer**: {ground_truth}

Evaluate this question-answer pair. Output a valid JSON object."""
